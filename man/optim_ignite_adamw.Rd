% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ignite.R
\name{optim_ignite_adamw}
\alias{optim_ignite_adamw}
\title{LibTorch implementation of AdamW}
\usage{
optim_ignite_adamw(
  params,
  lr = 0.001,
  betas = c(0.9, 0.999),
  eps = 1e-08,
  weight_decay = 0.01,
  amsgrad = FALSE
)
}
\description{
For further details regarding the algorithm we refer to
\href{https://arxiv.org/abs/1711.05101}{Decoupled Weight Decay Regularization}
}
\section{Methods}{

TODO:
}

\section{Fields}{

}

\examples{
if (torch_is_installed()) {
\dontrun{
optimizer <- optim_ignite_adamw(model$parameters(), lr = 0.1)
optimizer$zero_grad()
loss_fn(model(input), target)$backward()
optimizer$step()
}
}
}
